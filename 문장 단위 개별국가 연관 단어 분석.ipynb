{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7332580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a5fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\target_data\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook')\n",
    "DATA_PATH = os.getcwd() + r'\\target_data'\n",
    "print(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a671da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(DATA_PATH, '*.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4dca232",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "for source in files:\n",
    "    temp_df = pd.read_excel(source, engine='openpyxl')\n",
    "    all_dfs.append(temp_df)\n",
    "df = pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87af3cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>학교명</th>\n",
       "      <th>등급</th>\n",
       "      <th>지문</th>\n",
       "      <th>외국인인명</th>\n",
       "      <th>국가명</th>\n",
       "      <th>민족명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>경희대</td>\n",
       "      <td>5</td>\n",
       "      <td>장민: 어제 요리 프로그램에서 제철 음식을 가지고 누가 더 맛 있게 만드는지 대결을...</td>\n",
       "      <td>장민/한나</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경희대</td>\n",
       "      <td>5</td>\n",
       "      <td>흐엉: 장민, 이 제육볶음 좀 먹어 봐. 어제 마을 장터에 갔는데 직접 만든 고추장...</td>\n",
       "      <td>장민</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경희대</td>\n",
       "      <td>5</td>\n",
       "      <td>은영: 승진 시험 준비는 잘 되어 가?\\n상진: 그냥 그래. 요즘 일도 공부도 손에...</td>\n",
       "      <td>상진</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경희대</td>\n",
       "      <td>5</td>\n",
       "      <td>의학 전문가: 여러분은 어떻게 휴식을 하십니까? 집에서 텔레비전을 보면서 쉬신다고요...</td>\n",
       "      <td>윤태훈</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>경희대</td>\n",
       "      <td>5</td>\n",
       "      <td>예술 교육은 우리의 삶에 어떤 영향을 줄까요? 그에 대한 하나의 대답으로 콜롬비아의...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>콜롬비아</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   학교명 등급                                                 지문  외국인인명   국가명  민족명\n",
       "0  경희대  5  장민: 어제 요리 프로그램에서 제철 음식을 가지고 누가 더 맛 있게 만드는지 대결을...  장민/한나   NaN  NaN\n",
       "1  경희대  5  흐엉: 장민, 이 제육볶음 좀 먹어 봐. 어제 마을 장터에 갔는데 직접 만든 고추장...     장민   NaN  NaN\n",
       "2  경희대  5  은영: 승진 시험 준비는 잘 되어 가?\\n상진: 그냥 그래. 요즘 일도 공부도 손에...     상진   NaN  NaN\n",
       "3  경희대  5  의학 전문가: 여러분은 어떻게 휴식을 하십니까? 집에서 텔레비전을 보면서 쉬신다고요...    윤태훈   NaN  NaN\n",
       "4  경희대  5  예술 교육은 우리의 삶에 어떤 영향을 줄까요? 그에 대한 하나의 대답으로 콜롬비아의...    NaN  콜롬비아  NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426b3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df = df['지문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40eb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장 분리 : . 과 ? 를 이용해서 간단히 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e92f5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df = [ cell.replace('\\n','') for cell in cell_df]\n",
    "cell_df = [ cell.replace('.','.$') for cell in cell_df]\n",
    "cell_df = [ cell.replace('?','?$') for cell in cell_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca97c289",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences_in_cell = [cell.split('$') for cell in cell_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a932976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "for cell in sentences_in_cell:\n",
    "    for sent in cell:\n",
    "        if len(sent) > 2:\n",
    "            all_sentences.append(sent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a3ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTagger\n",
    "from Utagger.bin.utagger_py import UTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4916062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\Utagger\\한국어교재지문\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\Utagger\\한국어교재지문')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81795971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python call utagger function\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\Utagger\\Hlxcfg.txt\n"
     ]
    }
   ],
   "source": [
    "dllpath = r'../bin/UTaggerR64.dll'\n",
    "cfgpath = r'../Hlxcfg.txt'\n",
    "\n",
    "rt = UTagger.Load_global(dllpath, cfgpath)\n",
    "ut = UTagger(0) # 0은 객체 고유번호. 0~99 지정 가능. 같은 번호로 여러번 생성하면 안됨. 한 스레드당 하나씩 지정 필요.\n",
    "rt = ut.new_ucma() #객체 생성. 객체가 있어야 유태거 이용 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e47f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddaa1ec4032429eadaab18f0a7b7e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_utagging = [ut.tag_line(sent,3) for sent in tqdm(all_sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e546008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.release_ucma() #객체 해제\n",
    "UTagger.Release_global() #사전 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b6077d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 어깨번호 정제하고자 할 때 사용, 어깨번호는 여러숫자로 구성될 수 있으므로 마지막 2개만 사용\n",
    "def cutSemanticNum(word, all=False): # all : True이면 의미숫자를 다 잘라버림, False이면 두글자만 남김\n",
    "    splitted = word.split('__')\n",
    "    \n",
    "    if len(splitted) == 1: # __ 구분자가 없는단어는 원 단어 그대로 반환\n",
    "        return word\n",
    "    \n",
    "    if all==True:\n",
    "        return splitted[0]\n",
    "    \n",
    "    out_word = splitted[0]+'__'+splitted[1][-2:]\n",
    "    return out_word    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be884882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utagger 가 생성한 한 어절에서 + 단위로 형태소를 자른 후 / 단위로 어휘와 태그를 분석\n",
    "def utagging_to_simple_tagging(utg):\n",
    "    #outlier가 발견되어 제거함\n",
    "    utg = utg.replace('NNG\\n','NNG')\n",
    "    \n",
    "    temp_wordset = utg.split('+') # utagger 가 생성한 결과에서 + 단위로 잘라줌\n",
    "   \n",
    "    wordset = []\n",
    "    for word_tag in temp_wordset:\n",
    "        seplist = word_tag.split('/') #/ 로 잘라지지 않는 경우에 대한 예외처리\n",
    "        if len(seplist) <= 1 :\n",
    "            continue\n",
    "        else :\n",
    "            wordset.append(seplist)\n",
    "    if len(wordset) <= 0:\n",
    "        return None\n",
    "   \n",
    "    try:\n",
    "        first_word = wordset[0][0]\n",
    "        first_tag = wordset[0][1]\n",
    "    except:\n",
    "        print(\"예외처리 : \", wordset)\n",
    "    \n",
    "    #동사(VV), 형용사(VA)로 시작하면 바로 첫 단어만 내보냄\n",
    "    if first_tag.startswith('VV') or first_tag.startswith('VA'):\n",
    "        return (first_word, first_tag)\n",
    "    \n",
    "    if len(wordset) == 1: #한 단어인 경우 \n",
    "         #명사류, 부사, 한글자 이상의 외국어는 사용\n",
    "        if first_tag.startswith('NNP') or first_tag.startswith('NNG') or first_tag.startswith('MAG') or (first_tag.startswith('SL') and len(first_word)>1) :\n",
    "            #if word_tag[1].startswith('SL'):\n",
    "            #            print(word_tag[0])\n",
    "            return (first_word, first_tag)\n",
    "\n",
    "    else: #여러 단어인 경우 \n",
    "        if first_tag.startswith('NNP') or first_tag.startswith('NNG') or first_tag.startswith('SL') or first_tag.startswith('XPN'): #첫 단어가 다음과 같으면\n",
    "            output = []\n",
    "            \n",
    "            if first_tag.startswith('XPN'): #XPN+NNG 는 합쳐서 NNG로\n",
    "                second_word = wordset[1][0]\n",
    "                second_tag = wordset[1][1]\n",
    "                if second_tag.startswith('NNG'):\n",
    "                        output.append((cutSemanticNum(first_word,True)+second_word, second_tag))\n",
    "                        #print(output[0])\n",
    "                return output\n",
    "            \n",
    "            for word_tag in wordset: #XPN+NNG 로 반환해야함--> NNG로\n",
    "                if word_tag[1].startswith('NNP') or word_tag[1].startswith('NNG') or (word_tag[1].startswith('SL') and len(word_tag[0])>1): #명사류를 찾음\n",
    "                    #if word_tag[1].startswith('SL'): #지울 것\n",
    "                    #    print(word_tag[0])\n",
    "                    output.append((word_tag[0], word_tag[1]))\n",
    "            return output\n",
    "\n",
    "    return None\n",
    "\n",
    "#문장 전체를 받아서 (단어,태그) 튜플 리스트로 반환\n",
    "def remain_available_words(doc): \n",
    "    result = []\n",
    "    for utg in doc.split(' '):\n",
    "        simple_tagged = utagging_to_simple_tagging(utg)\n",
    "        if simple_tagged == None:\n",
    "            continue\n",
    "                \n",
    "        if str(type(simple_tagged)) ==\"<class 'tuple'>\":\n",
    "            result.append(simple_tagged)\n",
    "        else :\n",
    "            for word_tag in simple_tagged:\n",
    "                result.append(word_tag)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a521ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tagging = [remain_available_words(sent) for sent in sent_utagging]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f0b3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 수집\n",
    "os.chdir(r'C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook')\n",
    "DATA_PATH = os.getcwd()\n",
    "filename = DATA_PATH+r'\\불용어목록.xlsx'\n",
    "stopword_df = pd.read_excel(filename, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40d478c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 제거 필터\n",
    "stopword = list(stopword_df['불용어'])\n",
    "def stopword_filter(cell):\n",
    "    output = []\n",
    "    for word, tag in cell:\n",
    "        if word not in stopword:\n",
    "            output.append((word,tag))\n",
    "    return output      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ffeb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 제거\n",
    "sent_tagging = [stopword_filter(cell) for cell in sent_tagging]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c874699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유 태그 수 : 6\n"
     ]
    }
   ],
   "source": [
    "#태그:빈도 사전구성\n",
    "tag_freq_dic = {}\n",
    "for cell in sent_tagging:\n",
    "    for word, tag in cell:\n",
    "        tag_freq_dic[tag] = tag_freq_dic.get(tag, 0) + 1\n",
    "print(\"고유 태그 수 : %d\" % len(tag_freq_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b43dbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어:태그 사전구성\n",
    "word_tag_dic = {}\n",
    "for sent in sent_tagging:\n",
    "    for word, tag in sent:\n",
    "        word_tag_dic[word] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8948eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#셀내의 튜플 리스트에서 워드만 추출\n",
    "def word_selector(cell):\n",
    "    output = []\n",
    "    for word, tag in cell:\n",
    "        if word not in stopword:\n",
    "            output.append(word)\n",
    "    return output      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48c773a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_wordlist = [word_selector(cell) for cell in sent_tagging]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1469b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 수 :  11610\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "print(\"문장 수 : \", len(sent_wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "648d3d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 출현 수 : 91094\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for cell in sent_wordlist:\n",
    "    cnt += len(cell)\n",
    "print('단어 출현 수 :', cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1d8d361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유 단어 수 : 11275\n"
     ]
    }
   ],
   "source": [
    "#단어:빈도 사전\n",
    "word_freq_dic = {}\n",
    "for cell in sent_wordlist:\n",
    "    for word in cell:\n",
    "        word_freq_dic[word] = word_freq_dic.get(word, 0) + 1\n",
    "print(\"고유 단어 수 : %d\" % len(word_freq_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcc9f75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상위단어 정렬 [(2883, '있__01'), (1039, '보__01'), (896, '사람'), (623, '같'), (539, '없__01'), (463, '많'), (433, '생각하'), (429, '좋__01'), (428, '남자__02'), (426, '여자__02'), (415, '한국__05'), (338, '일__01'), (337, '더__01'), (329, '말__01'), (322, '만들'), (297, '문제__06'), (291, '크__01'), (284, '잘__02'), (277, '가__01'), (276, '알'), (269, '듣__01'), (268, '사회__07'), (266, '시간__04'), (261, '받__01'), (254, '학생'), (250, '사회자'), (248, '오늘'), (242, '생각__01'), (236, '살__01'), (235, '들__01'), (232, '가지'), (231, '많이'), (223, '지금__03'), (214, '자신__01'), (211, '먹__02'), (207, '주__01'), (200, '또'), (199, '오__01'), (192, '경우__03'), (190, '중요하__02'), (189, '문화__01'), (188, '쓰__03'), (187, '아이__01'), (184, '따르__01'), (179, '안__02'), (178, '좀__02'), (173, '말하'), (173, '느끼__02'), (171, '필요하'), (171, '경제__04'), (170, '영화__01'), (166, '안녕하'), (163, '나오'), (163, '가장__01'), (162, '맞__01'), (161, '교수__06'), (158, '세계__02'), (157, '이야기'), (156, '음악__01'), (153, '사용하__03'), (151, '사실__04'), (150, '다양하__01'), (149, '말씀'), (147, '정도__11'), (147, '요즘'), (147, '나라__01'), (145, '음식'), (144, '돈__01'), (142, '친구__02'), (142, '최근'), (141, '바로__02'), (141, '교육'), (139, '찾'), (138, '모르'), (137, '생활'), (136, '진행자'), (134, '먼저'), (133, '한옥'), (132, '기자__05'), (131, '속__01'), (130, '모두__01'), (128, '정말__01'), (128, '이번__01'), (128, '가족__01'), (127, '집__01'), (127, '이유__04'), (126, '방법'), (126, '내용__02'), (126, '나누'), (125, '함께'), (125, '이제__01'), (125, '시대__02'), (125, '모습__01'), (124, '어렵'), (122, '기업__01'), (121, '의견__01'), (121, '선생님'), (118, '다__03'), (116, '앞'), (115, '내__02'), (114, '변화'), (113, '의미__02'), (113, '다시__01'), (113, '다르__01'), (112, '소비자'), (112, '상황__02'), (111, '쉽'), (111, '광고__02'), (110, '힘들'), (108, '전__08'), (108, '다음__01'), (107, '현재__02'), (107, '새롭'), (107, '마음__01'), (106, '활동__02'), (105, '처음'), (105, '관심__01'), (104, '만나'), (102, '전문가'), (101, '또한'), (100, '지역__03'), (100, '능력__02'), (99, '방식__01'), (99, '대학__01'), (99, '나타나'), (97, '전통__06'), (97, '삶'), (97, '도움'), (96, '시작하__01'), (96, '배우__01'), (95, '감사하__05'), (94, '높'), (91, '과정__03'), (90, '특히'), (90, '보이__02'), (89, '정보__06'), (89, '인간__01'), (89, '이상__05'), (89, '너무__01'), (88, '결과__02'), (87, '회사__04'), (87, '상품__03'), (86, '학교'), (86, '읽'), (86, '역사__04'), (86, '남__01'), (86, '공간__05'), (85, '인터넷'), (85, '왜__02'), (85, '얻__01'), (84, '표현'), (83, '날__01'), (82, '부르__01'), (81, '하나'), (81, '기술__01'), (80, '과학'), (79, '환경__02'), (79, '제품__02'), (79, '몸__01'), (78, '차이'), (77, '아주__01'), (76, '해결하'), (76, '물론__01'), (75, '질문'), (75, '부분__01'), (75, '발전__01'), (74, '힘__01'), (74, '커피'), (74, '살펴보'), (74, '드라마'), (73, '관계__05'), (72, '직접'), (71, '여성__01'), (71, '빠르'), (69, '인기__01'), (69, '이용하__01'), (69, '길__01'), (68, '필요'), (68, '에너지'), (68, '언어__01'), (68, '미래__02'), (68, '마을__01'), (68, '갖__01'), (67, '영향__04'), (67, '말씀하'), (67, '경기__11'), (67, '같이'), (66, '효과__01'), (66, '예술'), (66, '가치__06'), (65, '이해하__02'), (65, '손__01'), (65, '사진__07'), (64, '책__01'), (64, '우리나라'), (64, '드리__01'), (64, '뉴스'), (64, '눈__01'), (64, '노래__01'), (63, '자리__01'), (63, '역할'), (63, '서로__01'), (63, '동안__01'), (63, '도시__03'), (62, '옷__01'), (62, '실험'), (62, '세대__02'), (62, '노인__01'), (62, '계속__04'), (62, '개인__02'), (61, '입__01'), (61, '우선__02'), (61, '수업__04'), (61, '분야'), (61, '모시'), (61, '들어가__01'), (61, '다니'), (61, '국가__01'), (61, '과거__03'), (60, '외국인'), (59, '한국어'), (59, '주제__04'), (59, '작품__01'), (59, '안__01'), (59, '세상__01'), (59, '기능__03'), (59, '국민'), (58, '지구__04'), (58, '일하'), (58, '영어__02'), (58, '보내'), (58, '물건'), (58, '마지막'), (57, '한국인'), (56, '좋아하'), (56, '서울__01'), (56, '살아가'), (56, '사랑__01'), (56, '발표__01'), (56, '대부분'), (56, '노력__01'), (56, '나이__01'), (56, '꼭__03'), (56, '건강__03'), (56, '가능하'), (55, '형태'), (55, '현상__04'), (55, '재미있'), (55, '잘하'), (55, '연구__03'), (55, '비슷하__02'), (55, '물__01'), (55, '대상__11'), (55, '넘__01'), (55, '결국'), (54, '프로그램'), (54, '중독__01'), (54, '원인__02'), (54, '얼마나'), (54, '어머니__01'), (54, '말씀드리'), (54, '긍정적'), (53, '활용하'), (53, '즐기__01'), (53, '이루__01'), (53, '쓰__01'), (53, '소비__05'), (53, '바라__01'), (53, '매우__01'), (53, '두__01'), (53, '동물'), (53, '나가'), (52, '중국__01'), (52, '제도__01'), (52, '장면__04'), (52, '잡__01'), (52, '일어나'), (52, '방송__01'), (52, '느낌'), (52, '나__01'), (52, '그리__02'), (51, '현실__02'), (51, '인재__02'), (51, '운동__02'), (51, '없이'), (51, '시민'), (51, '반응'), (51, '남__04'), (50, '호랑이'), (50, '행동'), (50, '오히려'), (50, '소설__03'), (50, '못__04'), (50, '뇌__03'), (49, '할머니'), (49, '창의력'), (49, '지나'), (49, '조사__30'), (49, '자료__03'), (49, '알아보'), (49, '알리'), (49, '사라지'), (49, '봉사__03'), (49, '대표적'), (49, '늘어나'), (49, '노력하__01'), (49, '구체적'), (48, '증가하__01'), (48, '결혼'), (48, '강연__03'), (47, '중심__01'), (47, '작__01'), (47, '인물'), (47, '이야기하'), (47, '성격__02'), (47, '부모님'), (47, '바뀌'), (47, '미국__03'), (47, '달라지'), (47, '공부하'), (47, '계시'), (47, '걷__02'), (47, '갖추'), (47, 'SNS'), (46, '특징'), (46, '취업'), (46, '조금__01'), (46, '적__02'), (46, '유지하__02'), (46, '원하__02'), (46, '부모__01'), (46, '모이__01'), (46, '대화__06'), (45, '평화__02'), (45, '정부__08'), (45, '젊'), (45, '자유__03'), (45, '일본__02'), (45, '스스로'), (45, '사'), (45, '부족하'), (45, '보통'), (45, '반면__02'), (45, '그때'), (45, '그냥'), (44, '주장__03'), (44, '주변__04'), (44, '제대로'), (44, '정하__03'), (44, '이후__02'), (44, '어리__03'), (44, '사건__01'), (44, '떨어지'), (44, '디자인'), (44, '글'), (44, '고민'), (43, '직장__05'), (43, '줄이'), (43, '죽__01'), (43, '조선__05'), (43, '올리__01'), (43, '엄마'), (43, '언론'), (43, '앵커__01'), (43, '아파트'), (43, '속도__01'), (43, '사이__01'), (43, '면__05'), (43, '뜻'), (43, '남편__01'), (43, '가격__03'), (42, '측면'), (42, '주로__01'), (42, '점점__01'), (42, '입장__04'), (42, '일부__02'), (42, '의식__03'), (42, '여행__02'), (42, '얼마'), (42, '소개하__01'), (42, '뒤__01'), (42, '당시__02'), (42, '나우루'), (42, '기회__03'), (42, '기준__03'), (42, '궁금하__01'), (42, '공부__01'), (42, '경험'), (42, '감독__02'), (41, '하루__01'), (41, '판소리'), (41, '지식__02'), (41, '정책__02'), (41, '자연__01'), (41, '비용__03'), (41, '발생하'), (41, '막__01'), (41, '대통령'), (41, '단어'), (41, '높아지'), (41, '관련'), (41, '공연__02'), (40, '혹시__01'), (40, '행복__02'), (40, '청소년'), (40, '전쟁'), (40, '쓰레기'), (40, '실제로'), (40, '반대__03'), (40, '마시'), (40, '걸리__01'), (40, '가정__06'), (39, '특별하'), (39, '준비하'), (39, '아기__01'), (39, '식량__03'), (39, '맛__01'), (39, '돕'), (39, '달리__01'), (39, '나쁘__01'), (39, '그대로'), (39, '경제적'), (39, '겪'), (39, '게임'), (38, '행복하'), (38, '지키__01'), (38, '준비'), (38, '소리__01'), (38, '서__01'), (38, '만약'), (38, '디지털'), (38, '덕분'), (37, '키우'), (37, '지나치'), (37, '적극적'), (37, '입'), (37, '이루어지'), (37, '모으'), (37, '마케팅'), (37, '다루__01'), (37, '낮'), (37, '길__02'), (37, '기사__10'), (36, '타__02'), (36, '준서'), (36, '주인공'), (36, '설명하'), (36, '박사__01'), (36, '바꾸'), (36, '모양__02'), (36, '끝__01'), (36, '끌'), (36, '그림__01'), (36, '교__88'), (36, '고기__01'), (36, '경쟁'), (36, '가수__11'), (35, '행사__01'), (35, '표현하'), (35, '치료'), (35, '참여하'), (35, '참__01'), (35, '직업'), (35, '전하'), (35, '자주__01'), (35, '이미__01'), (35, '이름'), (35, '열심히'), (35, '약자__02'), (35, '사례__05'), (35, '믿'), (35, '문자__02'), (35, '못하'), (35, '머리__01'), (35, '돌아가'), (35, '대학생'), (35, '단체__02'), (34, '청자'), (34, '찾아보'), (34, '짧'), (34, '작가__01'), (34, '자체__02'), (34, '자원__02'), (34, '인생__01'), (34, '움직이'), (34, '스트레스'), (34, '세계적'), (34, '선택하'), (34, '사고__12'), (34, '등장하__01'), (34, '끝나'), (34, '권리'), (34, '국제__02'), (34, '고려하__01'), (34, '거의__01'), (33, '혼자__01'), (33, '폭력'), (33, '평가__03'), (33, '전략__03'), (33, '자연스럽'), (33, '인구__01'), (33, '의하__01'), (33, '유명하__01'), (33, '오늘날'), (33, '아무리'), (33, '실제__02'), (33, '시험__03'), (33, '시청자'), (33, '시장__04'), (33, '쉬__03'), (33, '수준'), (33, '바쁘'), (33, '땅__01'), (33, '딸__01'), (33, '늘__01'), (33, '놓__01'), (33, '난민__02'), (33, '나무__01'), (32, '호칭__02'), (32, '한글__01'), (32, '프로슈머'), (32, '태어나'), (32, '제시하__01'), (32, '전체__01'), (32, '유행__02'), (32, '아이디어'), (32, '순간__03'), (32, '상태__01'), (32, '사업__04'), (32, '벗어나'), (32, '바람__01'), (32, '바다'), (32, '목소리'), (32, '더욱'), (32, '그리하'), (32, '교사__09'), (32, '걱정'), (31, '지아'), (31, '정신__12'), (31, '요소__04'), (31, '옛날'), (31, '여기'), (31, '알려지'), (31, '심각하__02'), (31, '신조어'), (31, '스포츠'), (31, '선수__05'), (31, '별로__01'), (31, '깊'), (31, '김__06'), (31, '결혼하'), (31, '개발'), (31, '강연자'), (30, '플라스틱'), (30, '토의__02'), (30, '토론자'), (30, '제공하__02'), (30, '자원__04'), (30, '자녀__01'), (30, '이익__02'), (30, '시작되__01'), (30, '생산'), (30, '상대방__02'), (30, '살리'), (30, '비__01'), (30, '불편하__01'), (30, '분위기'), (30, '북한__03'), (30, '방향__01'), (30, '발전하__01'), (30, '발달하'), (30, '미치__02'), (30, '문학__01'), (30, '따뜻하'), (30, '노동__03'), (30, '갈등'), (30, '가르치__01'), (29, '해설__03'), (29, '한편'), (29, '잃'), (29, '일상__04'), (29, '일반__02'), (29, '이산가족'), (29, '위기__01'), (29, '외국__02'), (29, '왕__04'), (29, '영상__01'), (29, '아름답'), (29, '신__09'), (29, '세우__01'), (29, '변하'), (29, '반드시'), (29, '미디어'), (29, '맞추__01'), (29, '들어오'), (29, '대회__02'), (29, '대신__03'), (29, '넣'), (29, '관광__02'), (29, '과제__04'), (29, '강하__01'), (29, '갑자기'), (29, '감정__06'), (29, '가깝'), (28, '휴대폰'), (28, '학습'), (28, '피해__01'), (28, '콘텐츠'), (28, '지혜__02'), (28, '주민'), (28, '조건__02'), (28, '유럽__02'), (28, '위치__01'), (28, '외국어'), (28, '예전__01'), (28, '얼굴__01'), (28, '아내__01'), (28, '신문__10'), (28, '소중하'), (28, '설명'), (28, '선택'), (28, '보존하'), (28, '반__07'), (28, '마치__02'), (28, '도와주'), (28, '대표'), (28, '높이'), (28, '남성__01'), (28, '굉장히'), (28, '공공__02'), (28, '건물__03'), (28, '가치관'), (27, '줄어들'), (27, '정치__03'), (27, '정리하'), (27, '자유롭'), (27, '이어지'), (27, '위__01'), (27, '온실가스'), (27, '오르'), (27, '열리__02'), (27, '역시__01'), (27, '얘기'), (27, '앉'), (27, '아들'), (27, '실력__02'), (27, '선배'), (27, '서비스'), (27, '생물__01'), (27, '법__01'), (27, '방__07'), (27, '마찬가지'), (27, '낳__01'), (27, '꿈__01'), (27, '길이__01'), (27, '관하__02'), (27, '관련되'), (27, '가능성'), (26, '훨씬'), (26, '확인하'), (26, '항상'), (26, '팬__01'), (26, '칭찬'), (26, '찬성__01'), (26, '집단'), (26, '지하철'), (26, '지방__05'), (26, '존재하'), (26, '제일__04'), (26, '접하__01'), (26, '재미__01'), (26, '임금__03'), (26, '인사법__01'), (26, '유교__02'), (26, '온난화'), (26, '여름__01'), (26, '업무__02'), (26, '심하'), (26, '심리__01'), (26, '시선__03'), (26, '사용되'), (26, '불리__04'), (26, '받아들이'), (26, '바탕__01'), (26, '목적__03'), (26, '메가시티'), (26, '리포터'), (26, '대중__02'), (26, '달__03'), (26, '내리__01'), (26, '나타내'), (26, '기억__02'), (26, '그동안'), (26, '관객'), (26, '고민하'), (26, '고객__04'), (26, '계기__04'), (25, '진행되'), (25, '젊은이'), (25, '장애인'), (25, '인정하'), (25, '이해__06'), (25, '원래__01'), (25, '예측하'), (25, '연극'), (25, '양__20'), (25, '섬__03'), (25, '빨리'), (25, '분석하__02'), (25, '범죄'), (25, '묻__03'), (25, '맛있'), (25, '담__01'), (25, '기후__05'), (25, '기부__08'), (25, '구조__08'), (24, '해__01'), (24, '평가하'), (24, '차원__01'), (24, '조사하__12'), (24, '장__20'), (24, '의사소통'), (24, '원리__02'), (24, '요리__05'), (24, '옆'), (24, '쓰이__03'), (24, '신경__04'), (24, '시기__04'), (24, '숨__01'), (24, '소장__08'), (24, '사용__04'), (24, '사상__15'), (24, '부장__07'), (24, '밖'), (24, '문__05'), (24, '뜨겁'), (24, '농산물'), (24, '나무꾼'), (24, '기존'), (24, '기억하__02'), (24, '기본적'), (24, '기간__07'), (24, '구매하__02'), (24, '과연__01'), (24, '고용__03'), (24, '경향__02'), (23, '혜택'), (23, '현대'), (23, '파악하'), (23, '특성__01'), (23, '진행하'), (23, '지원하__01'), (23, '전화__07'), (23, '장소__05'), (23, '열__02'), (23, '아프'), (23, '아무래도'), (23, '상상력__01'), (23, '상당히'), (23, '산__01'), (23, '부정적'), (23, '병원__02'), (23, '벌__02'), (23, '버스__02'), (23, '밤__01'), (23, '민족'), (23, '무대__06'), (23, '많아지'), (23, '로봇'), (23, '동시__02'), (23, '대한민국'), (23, '논란'), (23, '기다리'), (23, '그중'), (23, '괜찮'), (23, '과일__01'), (23, '게다가'), (22, '화자__06'), (22, '한반도'), (22, '학원__02'), (22, '학습자'), (22, '편하'), (22, '토론__01'), (22, '탄수화물'), (22, '치__02'), (22, '차지하__01'), (22, '전달하__02'), (22, '장점__02'), (22, '잇__01'), (22, '인터뷰'), (22, '인식'), (22, '이웃'), (22, '응답하'), (22, '요구하'), (22, '아래__01'), (22, '신체__02'), (22, '신입__03'), (22, '수출__03'), (22, '수많'), (22, '사원__04'), (22, '사랑하'), (22, '빠지__02'), (22, '비싸'), (22, '보도__04'), (22, '버리__01'), (22, '문화유산'), (22, '무역__02'), (22, '맡__01'), (22, '마련하'), (22, '리포트'), (22, '기__21'), (22, '국수__01'), (22, '국내__02'), (22, '공유하__01'), (22, '개발하'), (22, '가슴__01'), (22, '가게'), (21, '화__06'), (21, '해결__02'), (21, '편리하'), (21, '판매'), (21, '태도__03'), (21, '커지'), (21, '체험'), (21, '전공__05'), (21, '인류__01'), (21, '여전히'), (21, '여유'), (21, '아직__01'), (21, '쌓이'), (21, '식품__01'), (21, '시키__01'), (21, '시설__03'), (21, '손님'), (21, '성향__02'), (21, '서양'), (21, '불__01'), (21, '분석__02'), (21, '부담__01'), (21, '복잡하'), (21, '문법__01'), (21, '매체'), (21, '떠오르'), (21, '떠나'), (21, '단순히'), (21, '늘'), (21, '그만큼'), (21, '거리__01'), (21, '각종'), (20, '화려하'), (20, '해양'), (20, '편지__02'), (20, '충분히'), (20, '찍__02'), (20, '질병__02'), (20, '직원__03'), (20, '중시하'), (20, '존재'), (20, '젓가락'), (20, '적절하'), (20, '응원'), (20, '유엔'), (20, '욕구'), (20, '왜냐하면'), (20, '올림픽'), (20, '올라가'), (20, '온도'), (20, '오래__02'), (20, '어제__01'), (20, '어려움'), (20, '양반__03'), (20, '신화__04'), (20, '시절__01'), (20, '수입__02'), (20, '소식__04'), (20, '상징하'), (20, '산업'), (20, '보다__02'), (20, '밥__01'), (20, '발달'), (20, '반영되'), (20, '문명__03'), (20, '목표'), (20, '똑같'), (20, '따지__01'), (20, '담기__01'), (20, '단계__03'), (20, '남녀'), (20, '나아가'), (20, '기관__11'), (20, '교실'), (20, '공유__02'), (20, '개인적'), (20, '개념'), (19, '흥미'), (19, '흔히'), (19, '효과적'), (19, '화폐'), (19, '핵심'), (19, '풀'), (19, '춤__01'), (19, '청계천'), (19, '지치__01'), (19, '전통적'), (19, '일반적'), (19, '인식하'), (19, '이전__03'), (19, '이상하'), (19, '이때'), (19, '의미하__02'), (19, '웃'), (19, '아침'), (19, '식사__03'), (19, '성공하'), (19, '선진국'), (19, '서울대학교'), (19, '붙'), (19, '보고서'), (19, '방금__01'), (19, '발명품'), (19, '발견하__01'), (19, '반영하'), (19, '반갑'), (19, '박__08'), (19, '맞춤__01'), (19, '들리__03'), (19, '드러내'), (19, '독특하'), (19, '낫__02'), (19, '남북'), (19, '날씨__01'), (19, '나중__01'), (19, '꽤__01'), (19, '기분__01'), (19, '기대__03'), (19, '국적__02'), (19, '구분하__03'), (19, '공정하__01'), (19, '고통'), (19, '결정하__01'), (19, '강의__02'), (19, '각자__02'), (19, '각각__01'), (19, 'TV'), (18, '흐름'), (18, '해외'), (18, '평균'), (18, '팔'), (18, '통일__02'), (18, '컴퓨터'), (18, '축제__01'), (18, '추구하__01'), (18, '차별'), (18, '차례__01'), (18, '질__08'), (18, '진짜'), (18, '지니'), (18, '지내__01'), (18, '전통문화'), (18, '작업__01'), (18, '자세__02'), (18, '일으키'), (18, '일상생활'), (18, '인사__02'), (18, '인문학'), (18, '원작'), (18, '엄청나'), (18, '어른__01'), (18, '소통__02'), (18, '사회적'), (18, '뽑'), (18, '불황__01'), (18, '부자__08'), (18, '복지__10'), (18, '벌이'), (18, '반대하__01'), (18, '바이러스'), (18, '당하__01'), (18, '다하'), (18, '늦'), (18, '넓'), (18, '공동체'), (18, '건강하__02'), (18, '간단하__02'), (18, '가운데'), (17, '흐르__01'), (17, '현장__03'), (17, '피하'), (17, '풍부하'), (17, '표절'), (17, '팀__01'), (17, '찾아오'), (17, '지정하__05'), (17, '지원__02'), (17, '줄리앙'), (17, '주위__02'), (17, '조절하__02'), (17, '점차__02'), (17, '적성__05'), (17, '저렴하')]\n"
     ]
    }
   ],
   "source": [
    "word_freq = []\n",
    "for key, value in word_freq_dic.items():\n",
    "    word_freq.append((value, key))\n",
    "word_freq.sort(reverse=True)\n",
    "print(\"상위단어 정렬\", word_freq[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "053d0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 붙이기\n",
    "cell_wordjoin = [' '.join(cutSemanticNum(word) for word in cell) for cell in sent_wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78435118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#국가 목록\n",
    "country_list = ['중국', '미국', '일본', '나우루', '영국', '호주', '스페인', '독일', '인도', '그리스', '러시아', '프랑스', '노르웨이', '콜롬비아', '이탈리아', '브라질', '몽골', '태국', '이란', '몰디브', '모나코', '필리핀', '파라과이', '투발루', '코스타리카', '케냐', '캐나다', '자메이카', '이집트', '예멘', '에티오피아', '스웨덴', '부탄', '베트남', '라오스', '파나마', '탄자니아', '칠레', '인도네시아', '스위스', '스리랑카', '뉴질랜드', '나이지리아', '과테말라']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2957ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 리스트에 대한 쌍 조합 튜플을 반환\n",
    "def get_pairs_from_list(lst):\n",
    "    pairs = []\n",
    "    unique = list(set(lst)) #리스트 내 중복 제거\n",
    "    lst_len = len(unique)\n",
    "    for i in range(lst_len):\n",
    "        if i==(lst_len-1):\n",
    "            break\n",
    "        subset = unique[i+1:]\n",
    "\n",
    "        for item in subset:\n",
    "            pairs.append((unique[i], item))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98735741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#국가명으로 연관단어 네트워크 분석\n",
    "def country_semantic_network(country):\n",
    "    #대상 셀 선정\n",
    "    target_cell_wordjoin = [cell for cell in cell_wordjoin if country in cell]\n",
    "    #단어 합치기\n",
    "    target_cell_wordlist = [cell.split(\" \") for cell in target_cell_wordjoin]\n",
    "    word_dic = {}\n",
    "    for cell in target_cell_wordlist:\n",
    "        for word in cell:\n",
    "            word_dic[word] = word_dic.get(word, 0) + 1\n",
    "    print(\"총 단어 수 : %d\" % len(word_dic))\n",
    "    word_freq = []\n",
    "    for key, value in word_dic.items():\n",
    "        word_freq.append((value, key))\n",
    "    word_freq.sort(reverse=True)\n",
    "    #네트워크 생성, gephi를 위한 source-target 생성\n",
    "    edges = [get_pairs_from_list(cell) for cell in target_cell_wordlist]\n",
    "    G = nx.Graph()\n",
    "    for comb in edges:\n",
    "        for source, dest in comb:\n",
    "            if G.has_edge(source, dest):\n",
    "                G[source][dest]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(source, dest, weight=1)\n",
    "    print(\"생성된 그래프 노드 수: %d, 엣지 수 : %d\" %(G.number_of_nodes(), G.number_of_edges()))\n",
    "    ####degree centrality 추출 및 소팅(시간 소요됨)\n",
    "    start = time.time()\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    print(\"네트워크 분석 완료 time : %.2f seconds\" % (time.time()-start))\n",
    "    #####degree 추출 및 소팅\n",
    "    degree = G.degree()\n",
    "    degree_freq = []\n",
    "    for key, value in degree:\n",
    "        degree_freq.append((value, key))\n",
    "    degree_freq.sort(reverse=True)\n",
    "    #print(\"상위 degree\", degree_freq[:100])\n",
    "    \n",
    "    #결과 데이터 생성\n",
    "    country_df = pd.DataFrame()\n",
    "    country_df = pd.DataFrame(columns=['품사','단어','출현빈도','출현빈도/품사빈도','연결단어수','연결중심성','매개중심성','분석범위'])\n",
    "    for dfreq, word in degree_freq[:200] :\n",
    "        country_df = country_df.append({'품사':word_tag_dic[word],'단어':word,'출현빈도':word_dic[word],'연결단어수':dfreq,'연결중심성':degree_centrality[word],'매개중심성':betweenness_centrality[word],'분석범위':country,'출현빈도/품사빈도':word_freq_dic[word]/tag_freq_dic[word_tag_dic[word]]}, ignore_index=True)\n",
    "\n",
    "    DATA_PATH = os.getcwd() + r'\\save_data'\n",
    "    filename = DATA_PATH+'\\문장단위국가_'+country+'.xlsx'\n",
    "    country_df.to_excel(filename)\n",
    "    print(\"%s 저장 완료!\" %filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14416c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== 중국 분석 시작 =====================\n",
      "총 단어 수 : 481\n",
      "생성된 그래프 노드 수: 481, 엣지 수 : 4639\n",
      "네트워크 분석 완료 time : 0.98 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_중국.xlsx 저장 완료!\n",
      "================== 중국 분석 종료 =====================\n",
      "\n",
      "================== 미국 분석 시작 =====================\n",
      "총 단어 수 : 448\n",
      "생성된 그래프 노드 수: 448, 엣지 수 : 3831\n",
      "네트워크 분석 완료 time : 0.69 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_미국.xlsx 저장 완료!\n",
      "================== 미국 분석 종료 =====================\n",
      "\n",
      "================== 일본 분석 시작 =====================\n",
      "총 단어 수 : 362\n",
      "생성된 그래프 노드 수: 362, 엣지 수 : 3153\n",
      "네트워크 분석 완료 time : 0.52 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_일본.xlsx 저장 완료!\n",
      "================== 일본 분석 종료 =====================\n",
      "\n",
      "================== 나우루 분석 시작 =====================\n",
      "총 단어 수 : 223\n",
      "생성된 그래프 노드 수: 223, 엣지 수 : 1687\n",
      "네트워크 분석 완료 time : 0.22 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_나우루.xlsx 저장 완료!\n",
      "================== 나우루 분석 종료 =====================\n",
      "\n",
      "================== 영국 분석 시작 =====================\n",
      "총 단어 수 : 157\n",
      "생성된 그래프 노드 수: 157, 엣지 수 : 1172\n",
      "네트워크 분석 완료 time : 0.09 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_영국.xlsx 저장 완료!\n",
      "================== 영국 분석 종료 =====================\n",
      "\n",
      "================== 호주 분석 시작 =====================\n",
      "총 단어 수 : 91\n",
      "생성된 그래프 노드 수: 91, 엣지 수 : 764\n",
      "네트워크 분석 완료 time : 0.03 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_호주.xlsx 저장 완료!\n",
      "================== 호주 분석 종료 =====================\n",
      "\n",
      "================== 스페인 분석 시작 =====================\n",
      "총 단어 수 : 67\n",
      "생성된 그래프 노드 수: 67, 엣지 수 : 411\n",
      "네트워크 분석 완료 time : 0.02 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_스페인.xlsx 저장 완료!\n",
      "================== 스페인 분석 종료 =====================\n",
      "\n",
      "================== 독일 분석 시작 =====================\n",
      "총 단어 수 : 85\n",
      "생성된 그래프 노드 수: 85, 엣지 수 : 575\n",
      "네트워크 분석 완료 time : 0.03 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_독일.xlsx 저장 완료!\n",
      "================== 독일 분석 종료 =====================\n",
      "\n",
      "================== 인도 분석 시작 =====================\n",
      "총 단어 수 : 109\n",
      "생성된 그래프 노드 수: 109, 엣지 수 : 608\n",
      "네트워크 분석 완료 time : 0.02 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_인도.xlsx 저장 완료!\n",
      "================== 인도 분석 종료 =====================\n",
      "\n",
      "================== 그리스 분석 시작 =====================\n",
      "총 단어 수 : 122\n",
      "생성된 그래프 노드 수: 122, 엣지 수 : 879\n",
      "네트워크 분석 완료 time : 0.07 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_그리스.xlsx 저장 완료!\n",
      "================== 그리스 분석 종료 =====================\n",
      "\n",
      "================== 러시아 분석 시작 =====================\n",
      "총 단어 수 : 82\n",
      "생성된 그래프 노드 수: 82, 엣지 수 : 619\n",
      "네트워크 분석 완료 time : 0.01 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_러시아.xlsx 저장 완료!\n",
      "================== 러시아 분석 종료 =====================\n",
      "\n",
      "================== 프랑스 분석 시작 =====================\n",
      "총 단어 수 : 62\n",
      "생성된 그래프 노드 수: 62, 엣지 수 : 372\n",
      "네트워크 분석 완료 time : 0.01 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_프랑스.xlsx 저장 완료!\n",
      "================== 프랑스 분석 종료 =====================\n",
      "\n",
      "================== 노르웨이 분석 시작 =====================\n",
      "총 단어 수 : 34\n",
      "생성된 그래프 노드 수: 34, 엣지 수 : 174\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_노르웨이.xlsx 저장 완료!\n",
      "================== 노르웨이 분석 종료 =====================\n",
      "\n",
      "================== 콜롬비아 분석 시작 =====================\n",
      "총 단어 수 : 41\n",
      "생성된 그래프 노드 수: 41, 엣지 수 : 232\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_콜롬비아.xlsx 저장 완료!\n",
      "================== 콜롬비아 분석 종료 =====================\n",
      "\n",
      "================== 이탈리아 분석 시작 =====================\n",
      "총 단어 수 : 35\n",
      "생성된 그래프 노드 수: 35, 엣지 수 : 206\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_이탈리아.xlsx 저장 완료!\n",
      "================== 이탈리아 분석 종료 =====================\n",
      "\n",
      "================== 브라질 분석 시작 =====================\n",
      "총 단어 수 : 29\n",
      "생성된 그래프 노드 수: 29, 엣지 수 : 150\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_브라질.xlsx 저장 완료!\n",
      "================== 브라질 분석 종료 =====================\n",
      "\n",
      "================== 몽골 분석 시작 =====================\n",
      "총 단어 수 : 56\n",
      "생성된 그래프 노드 수: 56, 엣지 수 : 524\n",
      "네트워크 분석 완료 time : 0.01 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_몽골.xlsx 저장 완료!\n",
      "================== 몽골 분석 종료 =====================\n",
      "\n",
      "================== 태국 분석 시작 =====================\n",
      "총 단어 수 : 25\n",
      "생성된 그래프 노드 수: 25, 엣지 수 : 124\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_태국.xlsx 저장 완료!\n",
      "================== 태국 분석 종료 =====================\n",
      "\n",
      "================== 이란 분석 시작 =====================\n",
      "총 단어 수 : 34\n",
      "생성된 그래프 노드 수: 34, 엣지 수 : 289\n",
      "네트워크 분석 완료 time : 0.01 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_이란.xlsx 저장 완료!\n",
      "================== 이란 분석 종료 =====================\n",
      "\n",
      "================== 몰디브 분석 시작 =====================\n",
      "총 단어 수 : 20\n",
      "생성된 그래프 노드 수: 20, 엣지 수 : 103\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_몰디브.xlsx 저장 완료!\n",
      "================== 몰디브 분석 종료 =====================\n",
      "\n",
      "================== 모나코 분석 시작 =====================\n",
      "총 단어 수 : 18\n",
      "생성된 그래프 노드 수: 18, 엣지 수 : 84\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_모나코.xlsx 저장 완료!\n",
      "================== 모나코 분석 종료 =====================\n",
      "\n",
      "================== 필리핀 분석 시작 =====================\n",
      "총 단어 수 : 21\n",
      "생성된 그래프 노드 수: 21, 엣지 수 : 114\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_필리핀.xlsx 저장 완료!\n",
      "================== 필리핀 분석 종료 =====================\n",
      "\n",
      "================== 파라과이 분석 시작 =====================\n",
      "총 단어 수 : 20\n",
      "생성된 그래프 노드 수: 20, 엣지 수 : 102\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_파라과이.xlsx 저장 완료!\n",
      "================== 파라과이 분석 종료 =====================\n",
      "\n",
      "================== 투발루 분석 시작 =====================\n",
      "총 단어 수 : 12\n",
      "생성된 그래프 노드 수: 12, 엣지 수 : 35\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_투발루.xlsx 저장 완료!\n",
      "================== 투발루 분석 종료 =====================\n",
      "\n",
      "================== 코스타리카 분석 시작 =====================\n",
      "총 단어 수 : 19\n",
      "생성된 그래프 노드 수: 19, 엣지 수 : 139\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_코스타리카.xlsx 저장 완료!\n",
      "================== 코스타리카 분석 종료 =====================\n",
      "\n",
      "================== 케냐 분석 시작 =====================\n",
      "총 단어 수 : 22\n",
      "생성된 그래프 노드 수: 22, 엣지 수 : 140\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_케냐.xlsx 저장 완료!\n",
      "================== 케냐 분석 종료 =====================\n",
      "\n",
      "================== 캐나다 분석 시작 =====================\n",
      "총 단어 수 : 34\n",
      "생성된 그래프 노드 수: 34, 엣지 수 : 246\n",
      "네트워크 분석 완료 time : 0.02 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_캐나다.xlsx 저장 완료!\n",
      "================== 캐나다 분석 종료 =====================\n",
      "\n",
      "================== 자메이카 분석 시작 =====================\n",
      "총 단어 수 : 17\n",
      "생성된 그래프 노드 수: 17, 엣지 수 : 72\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_자메이카.xlsx 저장 완료!\n",
      "================== 자메이카 분석 종료 =====================\n",
      "\n",
      "================== 이집트 분석 시작 =====================\n",
      "총 단어 수 : 49\n",
      "생성된 그래프 노드 수: 49, 엣지 수 : 326\n",
      "네트워크 분석 완료 time : 0.02 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_이집트.xlsx 저장 완료!\n",
      "================== 이집트 분석 종료 =====================\n",
      "\n",
      "================== 예멘 분석 시작 =====================\n",
      "총 단어 수 : 11\n",
      "생성된 그래프 노드 수: 11, 엣지 수 : 39\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_예멘.xlsx 저장 완료!\n",
      "================== 예멘 분석 종료 =====================\n",
      "\n",
      "================== 에티오피아 분석 시작 =====================\n",
      "총 단어 수 : 33\n",
      "생성된 그래프 노드 수: 33, 엣지 수 : 336\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_에티오피아.xlsx 저장 완료!\n",
      "================== 에티오피아 분석 종료 =====================\n",
      "\n",
      "================== 스웨덴 분석 시작 =====================\n",
      "총 단어 수 : 11\n",
      "생성된 그래프 노드 수: 11, 엣지 수 : 46\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_스웨덴.xlsx 저장 완료!\n",
      "================== 스웨덴 분석 종료 =====================\n",
      "\n",
      "================== 부탄 분석 시작 =====================\n",
      "총 단어 수 : 12\n",
      "생성된 그래프 노드 수: 12, 엣지 수 : 39\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_부탄.xlsx 저장 완료!\n",
      "================== 부탄 분석 종료 =====================\n",
      "\n",
      "================== 베트남 분석 시작 =====================\n",
      "총 단어 수 : 38\n",
      "생성된 그래프 노드 수: 38, 엣지 수 : 212\n",
      "네트워크 분석 완료 time : 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_베트남.xlsx 저장 완료!\n",
      "================== 베트남 분석 종료 =====================\n",
      "\n",
      "================== 라오스 분석 시작 =====================\n",
      "총 단어 수 : 17\n",
      "생성된 그래프 노드 수: 17, 엣지 수 : 92\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_라오스.xlsx 저장 완료!\n",
      "================== 라오스 분석 종료 =====================\n",
      "\n",
      "================== 파나마 분석 시작 =====================\n",
      "총 단어 수 : 3\n",
      "생성된 그래프 노드 수: 3, 엣지 수 : 3\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_파나마.xlsx 저장 완료!\n",
      "================== 파나마 분석 종료 =====================\n",
      "\n",
      "================== 탄자니아 분석 시작 =====================\n",
      "총 단어 수 : 9\n",
      "생성된 그래프 노드 수: 9, 엣지 수 : 36\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_탄자니아.xlsx 저장 완료!\n",
      "================== 탄자니아 분석 종료 =====================\n",
      "\n",
      "================== 칠레 분석 시작 =====================\n",
      "총 단어 수 : 15\n",
      "생성된 그래프 노드 수: 15, 엣지 수 : 105\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_칠레.xlsx 저장 완료!\n",
      "================== 칠레 분석 종료 =====================\n",
      "\n",
      "================== 인도네시아 분석 시작 =====================\n",
      "총 단어 수 : 12\n",
      "생성된 그래프 노드 수: 12, 엣지 수 : 66\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_인도네시아.xlsx 저장 완료!\n",
      "================== 인도네시아 분석 종료 =====================\n",
      "\n",
      "================== 스위스 분석 시작 =====================\n",
      "총 단어 수 : 9\n",
      "생성된 그래프 노드 수: 9, 엣지 수 : 36\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_스위스.xlsx 저장 완료!\n",
      "================== 스위스 분석 종료 =====================\n",
      "\n",
      "================== 스리랑카 분석 시작 =====================\n",
      "총 단어 수 : 13\n",
      "생성된 그래프 노드 수: 13, 엣지 수 : 78\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_스리랑카.xlsx 저장 완료!\n",
      "================== 스리랑카 분석 종료 =====================\n",
      "\n",
      "================== 뉴질랜드 분석 시작 =====================\n",
      "총 단어 수 : 7\n",
      "생성된 그래프 노드 수: 7, 엣지 수 : 21\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_뉴질랜드.xlsx 저장 완료!\n",
      "================== 뉴질랜드 분석 종료 =====================\n",
      "\n",
      "================== 나이지리아 분석 시작 =====================\n",
      "총 단어 수 : 19\n",
      "생성된 그래프 노드 수: 19, 엣지 수 : 171\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_나이지리아.xlsx 저장 완료!\n",
      "================== 나이지리아 분석 종료 =====================\n",
      "\n",
      "================== 과테말라 분석 시작 =====================\n",
      "총 단어 수 : 9\n",
      "생성된 그래프 노드 수: 9, 엣지 수 : 36\n",
      "네트워크 분석 완료 time : 0.00 seconds\n",
      "C:\\Users\\Kislee\\PycharmProjects\\Korean_textbook\\save_data\\문장단위국가_과테말라.xlsx 저장 완료!\n",
      "================== 과테말라 분석 종료 =====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for country in country_list:\n",
    "    print(\"================== %s 분석 시작 =====================\" % country)\n",
    "    country_semantic_network(country)\n",
    "    print(\"================== %s 분석 종료 =====================\" % country)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1434caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#코드 끝."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
